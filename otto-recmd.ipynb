{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MbtowAcnw6wc"},"outputs":[],"source":["!pip install cuda-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6sJWwkNBwf2o"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from torch import nn, Tensor\n","import torch\n","\n","\n","#the function to pad the input sequence\n","from torch.utils.data import IterableDataset\n","\n","def generate_encoder_input_mask(dim: int, batchsize: int, num_heads: int) -> Tensor:\n","    \"\"\"\n","    Args:\n","        dim: int, for src masking this must be encoder sequence length (i.e.\n","              the length of the input sequence to the model)\n","    Return:\n","        A Tensor of shape (batch_size, num_heads, dim, dim)\n","    \"\"\"\n","    # mask = torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1)\n","    # mask = mask.unsqueeze(0)\n","    # mask = mask.repeat(batchsize * num_heads, 1, 1)\n","    mask = torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1)\n","    # mask = mask.repeat(batchsize * num_heads, 1, 1)\n","    return mask\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4JRA6vjwr1H"},"outputs":[],"source":["import torch\n","from torch import Tensor\n","import numpy as np\n","\n","\n","def ndcg_at_ip(predictions: Tensor, positive_index: Tensor, k: Tensor):\n","    \"\"\"\n","    Computes the discounted cumulative gain (DCG) at a given value of k.\n","\n","    Args:\n","    - scores: a tensor of relevance scores (in descending order) of recommended items.\n","    - positive_index: a positive integer specifying the number of top items to be considered.\n","\n","    Returns:\n","    - ndcg: a value of the DCG score.\n","    \"\"\"\n","    dcg = 0.0\n","    for i, p in enumerate(predictions[:k]):\n","        if p == positive_index:\n","            dcg += 1.0 / float(np.log2(i + 2.0))\n","\n","    return dcg\n","\n","def ndcg_batch(scores: Tensor, positive_batch: Tensor):\n","    batch_dcg = 0\n","    for i in range(len(positive_batch)):\n","        top_n = torch.topk(scores[i, :], 100).indices.tolist()\n","        score = ndcg_at_ip(top_n, positive_batch[i], 20)\n","        batch_dcg += score\n","    return batch_dcg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MRgVqu8wuS2"},"outputs":[],"source":["from torch.utils.data import IterableDataset\n","from torch.utils.data import DataLoader\n","import random\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","#parameter\n","negative_sample_size = 1\n","num_item = 364846 + 2\n","class JsonlDataset(IterableDataset):\n","    def __init__(self, filepaths):\n","        self.filepaths = filepaths\n","        random.shuffle(self.filepaths)\n","        # self.files = [pd.read_json(filepath, lines=True) for filepath in self.filepaths]\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        for file in self.filepaths:\n","            json_df = pd.read_json(file, lines=True)\n","            json_df['events'] = json_df['events'].apply(lambda x: [[d['ts'], d['type'], d['aid']] for d in x])\n","            print(json_df.head())\n","            numdata = json_df.to_numpy()\n","            random.shuffle(numdata)\n","            yield numdata\n","\n","class NumpyDataset(IterableDataset):\n","    def __init__(self, filepaths, batch_size):\n","        self.filepaths = filepaths\n","        self.batch_size = batch_size\n","        random.shuffle(self.filepaths)\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        for file in self.filepaths:\n","            data = np.load(file)\n","            random.shuffle(data)\n","            batches = np.array_split(data, len(data) // self.batch_size)\n","            for batch in batches:\n","                yield {\"items\": batch, \"negatives\": np.random.randint(1, num_item,\n","                                                                      size=(len(batch),\n","                                                                            len(batch[0][0]),\n","                                                                            negative_sample_size))}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZdKeazewwQm"},"outputs":[],"source":["import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","import json\n","import io\n","import math\n","import torch\n","from typing import Optional, Any, Union, Callable\n","import torch.nn as nn\n","from torch.nn.modules.normalization import LayerNorm\n","\n","from torch import Tensor\n","import torch.nn.functional as F\n","\n","\n","\n","# define the transformer model\n","class TimeSeriesTransformer(nn.Module):\n","    \"\"\"\n","        args:\n","\n","        shapes:\n","    \"\"\"\n","    def __init__(self,\n","                 num_item,\n","                 output_size,\n","                 hidden_size,\n","                 num_layers=4,\n","                 num_heads=4,\n","                 dim_feedforward_encoder=256,\n","                 dropout=0.2,\n","                 max_length=500,\n","                 layer_norm_eps: float = 1e-5,\n","                 device = None,\n","                 dtype = None\n","                 ):\n","        factory_kwargs = {'device': device, 'dtype': dtype}\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.nhead = num_heads\n","\n","        self.embedding_aid = nn.Embedding(num_embeddings=num_item + 1, embedding_dim=hidden_size, padding_idx=0, **factory_kwargs)\n","        self.embedding_type = nn.Embedding(num_embeddings=4, embedding_dim=hidden_size, padding_idx=0, **factory_kwargs)\n","        self.pos_embedding = nn.Embedding(num_embeddings=max_length, embedding_dim=hidden_size, **factory_kwargs)\n","        self.device = device\n","        encoderlayer = nn.TransformerEncoderLayer(\n","            d_model=hidden_size,\n","            nhead=num_heads,\n","            dim_feedforward=dim_feedforward_encoder,\n","            dropout=dropout,\n","            batch_first=True,\n","            **factory_kwargs\n","            )\n","        encoder_norm = LayerNorm(hidden_size, **factory_kwargs)\n","        self.encoder = nn.TransformerEncoder(encoder_layer=encoderlayer, num_layers=num_layers, norm=encoder_norm)\n","\n","        self.fc_type = nn.Linear(hidden_size, 3, **factory_kwargs)\n","\n","\n","    def forward(self, src_aid: Tensor, src_type: Tensor,\n","                src_mask: Tensor,\n","                src_key_padding_mask: Optional[Tensor] = None):\n","        src_padding_mask = (src_aid == 0)\n","        src_padding_mask = src_padding_mask.to(src_mask.dtype)\n","        src_padding_mask = src_padding_mask.to(device)\n","#         print(f\"src_type: {src_type}\")\n","        src_aid_embedding = self.embedding_aid(src_aid)\n","        src_type_embedding = self.embedding_type(src_type)\n","        src = src_aid_embedding * src_type_embedding\n","\n","        position_ids = torch.arange(0, src_aid.shape[-1])\n","        position_ids = position_ids.unsqueeze(0).to(device)\n","#         print(position_ids.device)\n","        position = self.pos_embedding(position_ids)\n","\n","        src = src + position\n","\n","        aid_type_embedding = self.encoder(src, mask=src_mask, src_key_padding_mask=src_padding_mask)\n","\n","        output_type = self.fc_type(aid_type_embedding)\n","        # Apply the softmax activation function\n","        output_type = F.softmax(output_type, dim=1)\n","\n","        return aid_type_embedding, output_type\n","\n","\n","    def predict(self, src_aid: Tensor, src_type: Tensor,\n","                src_mask: Optional[Tensor] = None,\n","                src_key_padding_mask: Optional[Tensor] = None):\n","        aid_type_embedding, type_probs = self(src_aid, src_type, src_mask=src_mask)\n","\n","        last_event_embeddings = aid_type_embedding[:, aid_type_embedding.size(1) - 1:, :]\n","        last_event_embeddings = last_event_embeddings.reshape(-1, last_event_embeddings.size(2))\n","        aid_scores = torch.matmul(last_event_embeddings, self.embedding_aid.weight.permute(1, 0)).squeeze(1)\n","#         print(f\"shape of last toke embeddings: {last_event_embeddings.shape}\")\n","#         print(f\"shape of self.embedding_aid.weight: {self.embedding_aid.weight.shape}\")\n","#         print(f\"shape of scores: {aid_scores.shape}\")\n","        type_probs = type_probs[:, type_probs.size(1) - 1:, :]\n","        type_probs = type_probs.reshape(-1, type_probs.size(2))\n","#         print(f\"shape of output_type: {type_probs.shape}\")\n","\n","        return aid_scores, type_probs\n","\n","    def train_step(self, src_aid: Tensor, src_type: Tensor,\n","                    negative_samples: Tensor,\n","                    src_mask: Optional[Tensor] = None):\n","\n","        aid_type_embedding, output_type = self(src_aid, src_type, src_mask)\n","\n","        target_type = src_type[:, 1:].reshape(-1)\n","        target_type = torch.nn.functional.one_hot(target_type, num_classes=4)\n","        target_type = target_type[:, 1:]# remove the 0 class\n","\n","        output_type = output_type[:, :-1, :]#during training, remove the predicted last token\n","        output_type = output_type.reshape(-1, output_type.size(2))\n","#         print(f\"output_type: {output_type}\")\n","        aid_type_embedding = aid_type_embedding[:, :-1, :]#during training, remove the attended last token\n","        aid_type_embedding = aid_type_embedding.reshape(-1, aid_type_embedding.size(2))  # (batch size * sequence_length, embedding dimension)\n","\n","        positives = src_aid[:, 1:]\n","        positives_embeddings = self.embedding_aid(positives)# (batch size, sequence_length, hidden_size)\n","        positives_embeddings = positives_embeddings.reshape(-1, positives_embeddings.size(2))  # (batch size * sequence_length)\n","#         print(f\"shape of positive embeddings: {positives_embeddings.shape}\")\n","        negative_samples = negative_samples[:, :-1]  # (batch size, sequence_length)\n","        negatives = negative_samples.reshape(-1)  # (batch size * sequence_length)\n","#         print(f\"shape of negatives: {negatives.shape}\")\n","        negatives_embeddings = self.embedding_aid(negatives)# (batch size * sequence_length, embedding dimension)\n","#         print(f\"shape of negatives embeddings: {negatives_embeddings.shape}\")\n","        positives_scores = (positives_embeddings * aid_type_embedding).sum(1)  # (batch size * sequence_length)\n","        negatives_scores = (negatives_embeddings * aid_type_embedding).sum(1)  # (batch size * sequence_length)\n","#         print(f\"shape of positive scores: {positives_scores.shape}\")\n","#         print(f\"shape of negatives scores: {negatives_scores.shape}\")\n","\n","        is_target = (positives != 0).float().reshape(-1)  # (batch size * sequence_length)\n","#         print(f\"shape of is_target: {is_target.shape}\")\n","#         print(f\"is_target sum: {is_target.sum()}\")\n","        aid_loss = (- torch.log(torch.sigmoid(positives_scores) + 1e-24) * is_target\n","                    - torch.log(1 - torch.sigmoid(negatives_scores) + 1e-24) * is_target)\n","        type_loss = - target_type * torch.log(output_type)\n","#         print(f\"shape of loss before sum: {aid_loss.shape}\")\n","#         print(f\"loss before sum: {aid_loss}\")\n","        loss = (aid_loss.sum() + type_loss.sum()) / (is_target.sum() * 2)\n","\n","#         print(f\"aid_loss.sum: {aid_loss.sum()} ***** type_loss.sum: {type_loss.sum()}\")\n","        return {'loss': loss}\n","\n","    def validation_step(self, src_aid: Tensor, src_type: Tensor,\n","                   src_mask: Optional[Tensor] = None):\n","        aid_scores, type_probs = self.predict(src_aid, src_type, src_mask = src_mask)\n","        aid_positive = src_aid[:, src_aid.size(1) - 1:].reshape(-1) #(batch size )\n","\n","        dcg = ndcg_batch(aid_scores, aid_positive)\n","\n","        # Get the maximum number in the second dimension (axis=1)\n","        type_prediction = torch.argmax(type_probs, dim=1)\n","        type_positive = src_type[:, src_type.size(1) - 1:].reshape(-1) #(batch size )\n","#         print(f\"shape of type_prediction: {type_prediction.shape}\")\n","#         print(f\"Shape of type_positive: {type_positive.shape}\")\n","        # Calculate the number of correctly predicted samples\n","        correct = (type_prediction == type_positive).sum()\n","#         print(f\"Shape of correct: {correct.shape}\")\n","#         print(f\"type_prediction: {type_prediction}\")\n","#         print(f\"type_positive: {type_positive}\")\n","        # accuracy = ( correct / type_positive.size(0)) * 100\n","\n","        return dcg, correct\n","\n","    def test_step(self, src_aid: Tensor, src_type: Tensor,\n","                        negative_samples: Tensor,\n","                        src_mask: Optional[Tensor] = None):\n","        aid_scores, type_probs = self.predict(src_aid, src_type, src_mask)\n","\n","        return None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBooU8FWwyUg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import time\n","import os\n","import gc\n","\n","# Define the hyperparameters\n","input_size = 364846 + 1\n","output_size = 364846 + 1\n","num_heads = 4\n","hidden_size = 32 * num_heads\n","num_layers = 2\n","dropout = 0.2\n","max_seq_length = 500 + 1\n","batch_size = 128\n","lr = 0.001\n","num_epochs = 5\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","# Create the model and the optimizer\n","model = TimeSeriesTransformer(num_item=input_size,\n","                              output_size=output_size,\n","                              hidden_size=hidden_size,\n","                              num_heads=num_heads,\n","                              num_layers=num_layers,\n","                              dropout=dropout,\n","                              max_length=max_seq_length,\n","                              device=device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","#loading a checkpoint\n","checkpoint = torch.load('checkpoint_0_.pt')\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(device)\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","criterion = nn.CrossEntropyLoss()\n","start_time = time.time()\n","total_loss = 0\n","\n","\n","# for root, dirs, files in os.walk('/kaggle/input/train-data/'):\n","#     for file in files:\n","#         trian_filepaths.append(os.path.join(root, file))\n","train_filepaths = []\n","# train_filepaths = ['train_seq_5.npy']\n","train_filepaths = ['train_seq_5.npy','train_seq_10.npy', 'train_seq_15.npy', 'train_seq_20.npy', 'train_seq_25.npy',\n","                  'train_seq_30.npy', 'train_seq_35.npy', 'train_seq_40.npy', 'train_seq_50.npy', 'train_seq_100.npy', 'train_seq_150.npy']\n","train_dataset = NumpyDataset(train_filepaths, batch_size)\n","\n","for epoch in range(num_epochs):\n","    train_dataset = NumpyDataset(train_filepaths, batch_size)\n","    batches = next(iter(train_dataset))\n","    print(f\"number of train batches:\")\n","    num_batch = 0\n","    for batch in batches:\n","        event_sequences = batch['items']\n","        negative_samples = torch.from_numpy(batch['negatives']).to(device)\n","        if len(event_sequences) == 1:\n","          print(\"break\")\n","          break\n","        aids_input = torch.from_numpy(np.array([event_sequence[0] for event_sequence in event_sequences]))\n","        types_input = torch.from_numpy(np.array([event_sequence[1] for event_sequence in event_sequences]))\n","        aids_input = aids_input.to(device)\n","        types_input = types_input.to(device)\n","\n","        mask = generate_encoder_input_mask(len(aids_input[0]), len(event_sequences), num_heads)\n","        mask = mask.to(device)\n","        Loss = model.train_step(aids_input, types_input, negative_samples, mask)\n","        optimizer.zero_grad()\n","        loss = Loss['loss']\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss\n","        num_batch += 1\n","    del train_dataset\n","    gc.collect()\n","        # Save a checkpoint every `save_interval` batches\n","    checkpoint_path = f'checkpoint_{epoch}.pt'\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, checkpoint_path)\n","\n","    # for root, dirs, files in os.walk('/kaggle/input/validation-data/'):\n","    #     for file in files:\n","    #         validation_files.append(os.path.join(root, file))\n","    validation_files=['validation_seq_5.npy','validation_seq_10.npy', 'validation_seq_15.npy', 'validation_seq_20.npy', 'validation_seq_25.npy',\n","                  'validation_seq_30.npy', 'validation_seq_35.npy', 'validation_seq_40.npy', 'validation_seq_50.npy', 'validation_seq_100.npy', 'validation_seq_150.npy']\n","    validation_dataset = NumpyDataset(validation_files, batch_size)\n","    batches = next(iter(validation_dataset))\n","    total_correct = 0\n","    total_dcg = 0\n","    total_seq = 0\n","    for batch in batches:\n","        event_sequences = batch['items']\n","        negative_samples = torch.from_numpy(batch['negatives'])\n","\n","        aids_input = torch.from_numpy(np.array([event_sequence[0] for event_sequence in event_sequences]))\n","        types_input = torch.from_numpy(np.array([event_sequence[1] for event_sequence in event_sequences]))\n","        aids_input = aids_input.to(device)\n","        types_input = types_input.to(device)\n","\n","        mask = generate_encoder_input_mask(len(aids_input[0]), len(event_sequences), num_heads)\n","        mask = mask.to(device)\n","        dcg, correct = model.validation_step(aids_input, types_input, mask)\n","        total_dcg += dcg\n","        total_correct += correct\n","        total_seq += len(event_sequences)\n","\n","    ndcg = total_dcg / total_seq\n","    accuracy = total_correct / total_seq\n","    del validation_dataset\n","    gc.collect()\n","    print(f\"ndcg: {ndcg}\")\n","    print(f\"accuracy: {accuracy}\")\n","    time_duration = time.time() - start_time\n","    print(time_duration)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNuFprJpR2Hq9QWUqlAj/k4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}